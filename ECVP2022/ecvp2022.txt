Visual foraging is a paradigm in which participants must find multiple targets among distracters. There are typically two different classes of target item and previous work (Kristj√°nsson, et al, 2014, PloS One 9.6) has shown that when search is hard participants tend to select targets in runs of one type, then the other. We have recently developed a generative model that requires only four parameters yet can fully account for human behaviour at the summary statistics level (Clarke, Hunt & Hughes, 2022, PloS Comp. Bio). In our new work, we investigate how well the model can account for human behaviour at the level of predicting which specific target will be selected during a trial. We find that our model is on average fairly accurate, although there is considerable variation in how predictable different participants are (range: [43%-69%]; chance = 11%) and that the feature foraging is easier to predict that conjunction (67% compared to 59%). On closer inspection, these differences appear to be primarily driven by differences in the weighting put on proximity between different participants and conditions. We also find some evidence that a subset of participants are carrying out some form of path-length minimization behaviour that is not yet captured by our model. Finally, in order to improve our model's predictions, we model how likely different items are to be selected as the first item in a trial. We find a bimodal distribution in which most participants start in the top left corner, while a subset favour initiating their search from the centre of the display. Overall, we find that our model does a good job of accounting for human behaviour in visual foraging tasks, and we demonstrate how we can learn more about human behaviour by investigating the cases in which our model fails to match with the empirical data. 